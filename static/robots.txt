# Robots.txt for Lusan Sapkota Portfolio
# https://www.lusansapkota.com.np/robots.txt

User-agent: *
Allow: /
Disallow: /admin/
Disallow: /api/private/
Disallow: /.git/
Disallow: /__pycache__/
Disallow: /migrations/
Disallow: /venv/
Disallow: /.env
Disallow: /config.py
Disallow: /requirements.txt
Disallow: /test*
Disallow: /debug/
Disallow: /search?
Disallow: /tmp/
Disallow: /cache/

# Allow important resources
Allow: /static/
Allow: /assets/
Allow: /*.css
Allow: /*.js
Allow: /*.jpg
Allow: /*.png
Allow: /*.gif
Allow: /*.svg
Allow: /*.webp
Allow: /*.ico
Allow: /*.pdf
Allow: /*.txt
Allow: /manifest.json
Allow: /sw.js

# Crawl delay for respectful crawling
Crawl-delay: 1

# Sitemaps
Sitemap: https://www.lusansapkota.com.np/static/sitemap.xml
Sitemap: https://wiki.lusansapkota.com.np/sitemap.xml
Sitemap: https://git.lusansapkota.com.np/sitemap.xml
Sitemap: https://donation.lusansapkota.com.np/sitemap.xml

# Google specific directives
User-agent: Googlebot
Allow: /
Crawl-delay: 1

# Bing specific directives
User-agent: Bingbot
Allow: /
Crawl-delay: 1

# Social Media Crawlers
User-agent: facebookexternalhit
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

User-agent: WhatsApp
Allow: /

User-agent: TelegramBot
Allow: /

# AI/ML Crawlers
User-agent: GPTBot
Disallow: /

User-agent: ChatGPT-User
Disallow: /

User-agent: CCBot
Disallow: /

User-agent: anthropic-ai
Disallow: /

User-agent: Claude-Web
Disallow: /

# Archive crawlers
User-agent: ia_archiver
Allow: /

User-agent: archive.org_bot
Allow: /